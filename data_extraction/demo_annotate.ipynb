{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from protobuf_to_dict import protobuf_to_dict\n",
    "import numpy as np\n",
    "import pickle\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_numpy(data: list) -> np.array:\n",
    "    arr = np.empty((len(data),len(data[0]), len(data[0][0])), np.float64)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[0])):\n",
    "            arr[i, j, :] = [data[i][j]['x'], data[i][j]['y'], data[i][j]['z']]\n",
    "    return arr\n",
    "\n",
    "def standardize_data(data, axis_, center=True, scale=True):\n",
    "    shape_ = list(data.shape)\n",
    "    shape_[axis_] = 1\n",
    "        \n",
    "    if center:\n",
    "        data = data - data.mean(axis=axis_).reshape(*shape_)\n",
    "    if scale:\n",
    "        data = data - data.min(axis=axis_).reshape(*shape_)\n",
    "        mm = data.max(axis=axis_) - data.min(axis=axis_)\n",
    "        mm = mm.reshape(*shape_)\n",
    "        data = data / (data.max(axis=axis_) - data.min(axis=axis_)).reshape(*shape_)\n",
    "\n",
    "    return data\n",
    "\n",
    "def to_sequential(data: np.ndarray, seq_length: int=10, axis: int=1) -> np.ndarray:\n",
    "    '''Transforms to sequential data\n",
    "\n",
    "        # sp_cls[0] = 1 if np.sum(np.abs(s[0, 13] - s[0, 14])) > 0.025 else 0\n",
    "        # txt = 'speaking' if np.sum(sp_cls)/2 >= 0.5 else 'not speaking'\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        The data to be processed\n",
    "    seq_length: int\n",
    "        The total number of consequent samples that would be used\n",
    "        to generate the sequential data\n",
    "    axis: int\n",
    "        The nex axis where the sequences would be put in\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        np.ndarray\n",
    "        The transformed sequential data\n",
    "\n",
    "    '''\n",
    "\n",
    "    shape_ = tuple(val - seq_length + 1 if i == 0 else val for i, val in enumerate(data.shape))\n",
    "    shape_ = shape_[:axis] + (seq_length,) + shape_[axis:]\n",
    "    seq_data = np.zeros(shape_)\n",
    "    for i in range(data.shape[0]-seq_length+1):\n",
    "        seq_data[i, :, :, :] = data[i:i+seq_length, :, :]\n",
    "    return seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_lip = [185, 184, 183, 191, \n",
    "             40, 74, 42, 80,\n",
    "             39, 73, 41, 81, \n",
    "             37, 72, 38, 82, \n",
    "             0, 11, 12, 13, \n",
    "             267, 302, 208, 312,\n",
    "             269, 303, 271, 311,\n",
    "             270, 304, 272, 310,\n",
    "             409, 408, 407, 415]\n",
    "\n",
    "lower_lip = [146, 77, 96, 95,\n",
    "             91, 90, 89, 88,\n",
    "             181, 180, 179, 178,\n",
    "             84, 85, 86, 87,\n",
    "             17, 16, 15, 14,\n",
    "             314, 315, 316, 317,\n",
    "             405, 404, 403, 402,\n",
    "             321, 320, 319, 318,\n",
    "             375, 307, 325, 324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30\n",
    "is_sequential = True\n",
    "seq_length_speak = 20\n",
    "is_pca = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clfs.pickle', 'rb') as f:\n",
    "    clfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pca.pickle', 'rb') as f:\n",
    "    pca = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_func = 'logspace'\n",
    "# weigh_val = None\n",
    "if weight_func == 'logspace':\n",
    "  weight_val = np.logspace(0, 4, num=seq_length_speak, base=2.0)\n",
    "  weight_val /= weight_val.sum()\n",
    "elif weight_func == 'linear':\n",
    "    weight_val = np.arange(1, seq_length_speak+1)/np.sum(np.arange(1, seq_length_speak + 1))\n",
    "else:\n",
    "  weigh_val = np.ones(seq_length_speak)/np.sum(seq_length_speak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60683/3816321701.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data = data / (data.max(axis=axis_) - data.min(axis=axis_)).reshape(*shape_)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb#ch0000010?line=126'>127</a>\u001b[0m   \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(inference_frame1)\u001b[39m.\u001b[39many():\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb#ch0000010?line=127'>128</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb#ch0000010?line=128'>129</a>\u001b[0m   \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49misnan(inference_frame2)\u001b[39m.\u001b[39many():\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb#ch0000010?line=129'>130</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/vision/Desktop/projects/data-extraction/data_extraction/demo_annotate.ipynb#ch0000010?line=130'>131</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "clf = clfs['Linear SVM']\n",
    "record_video = False\n",
    "theta_CLD = 7\n",
    "theta_CSD = 0.5\n",
    "color_idx = [(0,0,0), (0,0,0)]\n",
    "confidence_weight = np.arange(1, seq_length_speak+1)/np.sum(np.arange(1, seq_length_speak + 1))\n",
    "sp_cls = np.zeros(seq_length_speak)\n",
    "max_num_faces=2\n",
    "refine_landmarks=True\n",
    "min_detection_confidence=0.5\n",
    "min_tracking_confidence=0.5\n",
    "conf_analysis = {\n",
    "  'speaking': {\n",
    "    'count': 0,\n",
    "    'conf': []\n",
    "  },\n",
    "    'not_speaking': {\n",
    "    'count': 0,\n",
    "    'conf': []\n",
    "  }\n",
    "}\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=max_num_faces,\n",
    "        refine_landmarks=refine_landmarks,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    ) as face_mesh:\n",
    "    cap = cv2.VideoCapture('1.avi')\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened() == False):\n",
    "      print(\"Error opening video stream or file\")\n",
    "\n",
    "    if record_video:\n",
    "      # Read until video is completed\n",
    "      frame_width = int(cap.get(3))\n",
    "      frame_height = int(cap.get(4))\n",
    "        \n",
    "      size = (frame_width, frame_height)\n",
    "      out = cv2.VideoWriter('output_videos/fin_demo_4.avi', \n",
    "                          cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                          10, size)\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    seq_frames1 = np.zeros((seq_length, 478, 3))\n",
    "    seq_frames2 = np.zeros((seq_length, 478, 3))\n",
    "    now = time()\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "\n",
    "      # Capture frame-by-frame\n",
    "      ret, frame = cap.read()\n",
    "      # if time() - now < 15:\n",
    "      #   continue\n",
    "      if ret == True:\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        # image.flags.writeable = False\n",
    "        image = frame\n",
    "        # image = frame\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # Draw the face mesh annotations on the image.\n",
    "        # image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if results is None and len(results.multi_face_landmarks) != 2:\n",
    "          continue\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for i, face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "                # add facelandmarks to the keypoints listimage\n",
    "                # print(len(results.))\n",
    "                keypoints = protobuf_to_dict(face_landmarks)[\"landmark\"]\n",
    "\n",
    "\n",
    "                s = np.array([[i['x'], i['y'], i['z']] for i in keypoints])\n",
    "                anchorpoint = tuple([int(s[10][0]*cap.get(3)), int(s[10][1]*cap.get(4))])\n",
    "                s = np.expand_dims(s, axis=0)\n",
    "                if i == 0:\n",
    "                  if is_sequential:\n",
    "                    if count1 <= seq_length - 1:\n",
    "                      seq_frames1[count1] = s\n",
    "                      count1 += 1\n",
    "                    else:\n",
    "                      seq_frames1 = np.roll(seq_frames1, -1, axis=0)\n",
    "                      seq_frames1[seq_length-1] = s\n",
    "                  else:\n",
    "                    inference_frame1 = s.reshape(1, -1)\n",
    "                    \n",
    "                if i == 1:\n",
    "                  if is_sequential:\n",
    "                    if count2 <= seq_length - 1:\n",
    "                      seq_frames2[count2] = s\n",
    "                      count2 += 1\n",
    "                    else:\n",
    "                      seq_frames2 = np.roll(seq_frames2, -1, axis=0)\n",
    "                      seq_frames2[seq_length-1] = s\n",
    "                  else:\n",
    "                    inference_frame2 = s.reshape(1, -1)\n",
    "                  \n",
    "                if is_sequential:\n",
    "                  if i == 0:\n",
    "                    inference_frame1 = np.expand_dims(seq_frames1, axis=0)\n",
    "                    inference_frame1 = standardize_data(inference_frame1, axis_=2)\n",
    "                    inference_frame1 = inference_frame1.reshape(1, -1)\n",
    "                  elif i == 1:\n",
    "                    inference_frame2 = np.expand_dims(seq_frames2, axis=0)\n",
    "                    inference_frame2 = standardize_data(inference_frame2, axis_=2)\n",
    "                    inference_frame2 = inference_frame2.reshape(1, -1)\n",
    "\n",
    "                  # print(inference_frame.shape)\n",
    "                  # break\n",
    "                else:\n",
    "                  if i == 0:\n",
    "                    inference_frame1 = standardize_data(inference_frame1, axis_=1)\n",
    "                    inference_frame1 = inference_frame1.reshape(1, -1)\n",
    "                    \n",
    "                  elif i == 1:\n",
    "                    inference_frame2 = standardize_data(inference_frame2, axis_=1)\n",
    "                    inference_frame2 = inference_frame2.reshape(1, -1)\n",
    "                try:\n",
    "                  if np.isnan(inference_frame1).any():\n",
    "                    continue\n",
    "                  if np.isnan(inference_frame2).any():\n",
    "                    continue\n",
    "                except NameError:\n",
    "                  continue \n",
    "                \n",
    "                # fix this\n",
    "                \n",
    "                pred_text = \"waiting\"\n",
    "                if count1 == seq_length:    \n",
    "                  if i == 0:\n",
    "                    inference_frame = pca.transform(inference_frame1) if is_pca else inference_frame1\n",
    "                  elif i == 1:\n",
    "                    inference_frame = pca.transform(inference_frame2) if is_pca else inference_frame2\n",
    "\n",
    "\n",
    "                  y_pred = clf.predict(inference_frame)\n",
    "                  pred_text = \"facing\" if y_pred == 1 else \"not facing\"\n",
    "\n",
    "\n",
    "                sp_cls = np.roll(sp_cls, -1, axis=0)\n",
    "                lip_distance = np.abs(s[0, upper_lip, 1] - s[0, lower_lip, 1])\n",
    "                lip_distance = lip_distance/(lip_distance.max() - lip_distance.min())\n",
    "                sp_cls[seq_length_speak - 1] = 1 if np.sum(lip_distance) > theta_CLD else 0\n",
    "                decision_val = 'speaking' if np.sum(sp_cls * weight_val) >= theta_CSD else 'not speaking' # better result\n",
    "                diff = np.sum(np.abs(s[0, upper_lip, 1] - s[0, lower_lip, 1]))\n",
    "                \n",
    "                cv2.rectangle(image, (anchorpoint[0]-100, 5), (anchorpoint[0]+100, 60), color_idx[i], thickness=-1)\n",
    "\n",
    "                window_name = 'Image'\n",
    "\n",
    "                # font\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                # org\n",
    "                org = (anchorpoint[0]-85, 25)\n",
    "                \n",
    "                # fontScale\n",
    "                fontScale = 0.5\n",
    "                \n",
    "                # Blue color in BGR\n",
    "                color = (255, 0, 0)\n",
    "                \n",
    "                # Line thickness of 2 px\n",
    "                thickness = 1\n",
    "                confidence = np.sum(sp_cls * weight_val)\n",
    "                # decision_val = 'speaking' if confidence >= 0.5 else 'not speaking' # better result\n",
    "\n",
    "                confidence = confidence if decision_val == \"speaking\" else 1 - confidence\n",
    "                \n",
    "                if decision_val == 'speaking':\n",
    "                    conf_analysis['speaking']['count'] += 1\n",
    "                    conf_analysis['speaking']['conf'].append(confidence)\n",
    "                else:\n",
    "                    conf_analysis['not_speaking']['count'] += 1\n",
    "                    conf_analysis['not_speaking']['conf'].append(confidence)\n",
    "                \n",
    "                # Using cv2.putText() method\n",
    "                # image = cv2.putText(image, label_text[int(y_pred)], org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "                color_ = (0,255,0) if decision_val == \"speaking\" else (0,0,255)\n",
    "                # image = cv2.putText(image, f'CLD: {lip_distance.sum():.5f}', org, font, fontScale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "                # color_ = (0,255,0) if np.sum(sp_cls * weight_val) > 0.010 else (0,0,255)\n",
    "                # image = cv2.putText(image, f'CSD: {np.sum(sp_cls * weight_val):.5f}', (anchorpoint[0]-85, 45), font, fontScale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, f'User is: {decision_val}', (anchorpoint[0]-85, 25), font, fontScale, color_, thickness, cv2.LINE_AA)\n",
    "                # image = cv2.putText(image, f'Confidence is: {confidence*100:.2f}%', (anchorpoint[0]-85, 85), font, fontScale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "                image = cv2.putText(image, f'User is: {pred_text}', (anchorpoint[0]-85, 50), font, fontScale, (0,255,0) if pred_text == \"facing\" else (0,0,255), thickness, cv2.LINE_AA)\n",
    "\n",
    "        else:\n",
    "          continue\n",
    "      \n",
    "        if record_video:\n",
    "          out.write(image)\n",
    "        cv2.imshow('Frame',image)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "          break\n",
    "\n",
    "      # Break the loop\n",
    "      else: \n",
    "        break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "    if record_video:\n",
    "      out.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62b73c42d2f105e7c8e271bc8c2a39228b526503e98c09a606ae1cf3e987b1e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('data-extraction-WtZGDk9M-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
